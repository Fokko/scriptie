\begin{savequote}[75mm] 
To iterate is human, to recurse divine. \qauthor{L. Peter Deutsch} 
\end{savequote}

This research is concluded by the Research Question defined in Section \ref{sec1-researchquestions}. Subsequently, further research is presented which provides further uncovered research questions which have been exposed by the presented work.

The introduction given in Section \ref{chap1:introduction} illustrates the growth of information in today's society. The main goal of outlier detection is to provide automated extraction of possible valuable observations within a dataset which is too big or complex to be analyzed by traditional statical software. Instead, extracting potential outliers within these staggering amounts of data, a scalable approach is required. The background of outlier detection and a variety of useful applications is presented in Section \ref{sec1-motivation}, among which its use in the fields of financial transactions, sensor monitoring, quality control and more.

After evaluating different definitions, we acquire the definition of outlier detection as: `An outlier is an observation that deviates quantitatively from the majority of the observations, according to an outlier-selection algorithm'. Important is the notion of quantifying the outlierness of a particular outlier. Chapter \ref{chap2:background} provides a solid background on outlier detection in Section \ref{sec2:outlier}. The different types of outlier detection are introduced, and a set of potential algorithms is presented. Subsequently, as outlier detection is part of the field of Knowledge Discovery and Data Mining and the computational platform to scale and distribute the algorithm is rarely taken into account. Therefore the Web-scale paradigm is first introduced in Section \ref{sec2:webscale} and describes the computational models and tools which can be used  to parallelize and scale the process of outlier detection.

Chapter \ref{chap3:architecture} introduces the architecture which allows the application to run on a cluster of machines distributed across a data center. The underlying pattern is the Microservice pattern which consists of suites of independently deployable services. Apache Spark is used as the computational platform which enables large-scale processing. Spark also takes care of failing nodes in the cluster by restarting the task onto another worker. Apache Kafka is used as the data-source because of its ability to scale and divide load. Kafka acts as a message queue which integrates nicely with Spark Streaming to apply the algorithm as new messages are appended. All the services are deployed using Docker which enables fast and easy deployment on possibly heterogeneous hardware using abstraction.

Starting with Research sub-question \ref{sub-req1}; \emph{`Which general-purpose outlier detection algorithms can potentially be scaled out'}, a variety of the types and important outlier detection algorithms are given in Table \ref{tbl:overviewAlgorithms}. This boils down to two suitable algorithms in Section \ref{chap4:algorithm}, i.e. Local Outlier Factor (LOF) based algorithms and the Stochastic Outlier Selection (SOS) algorithm. The LOF algorithm is a widely used algorithm and extensions are proposed in a variety of papers. The SOS algorithm is chosen over the LOF algorithm because the latter requires many $k$-nearest neighbour queries which are difficult to implement efficiently in a map-reduce model. Beside that the ability to extract outliers is comparable.

Research sub-question \ref{sub-req2} focuses on the field of big-data and distributed computing to explore the possibilities of scaling; \emph{`Which computational engines are appropriate for outlier-detection in a big-data setting'}. As `big-data' is an ambiguous term, therefore a definition is in place, in Section \ref{sec2:webscale} we give the definition: `massively parallel software running on tens, hundreds, or even thousands of servers'. Many outlier detection algorithm do not take scalability into account and solely focus on the ability to detect outliers. The present goal is to scale outlier detection on a large pool of easily accessible virtualized resources, which can be dynamically reconfigured in order to adjust to a variable load. The infrastructure given in Chapter \ref{chap3:architecture} enables scaling the algorithm by adding or removing workers based on load or requirements. Packing the services inside Docker containers enables fast deployment onto a large number of machines. As the number of machines increases, it becomes more probable that one fails, therefore availability and coordination is provided by Apache Zookeeper, which provides reliable distributed coordination.

The last Research sub-question is \ref{sub-req3}; \emph{`How to adapt the algorithm to work with streams of data, rather than a static set'}. Data is generated faster and real-time data processing is required to act upon what is happening real time. By using the Spark Streaming library and the Apache Kafka data source this can be done in an efficient micro-batching characteristic. The number of observations which are taken and the interval between them is defined by a window which also allows windows to overlap.

Based on the results in Chapter \ref{chap5:results} a number of conclusions can be drawn. We observe that:
\begin{itemize} 
    \item The distributed implementation of outlier-detection is feasible and follows the computational complexity of the algorithm $\mathcal{O}(n^{2})$ as the function of the input size.
    \item The number of partitions of the RDD needs to be tuned to the size of the input and the number of worker nodes to utilize the resources in the cluster most optimal.
    \item The configuration of Apache Spark has to be tuned to the specifications of the systems to avoid unnecessary swapping, which induces significant overhead and slows down the computations.
\end{itemize}

All the computations within Spark are executed in stages. After each stage, synchronization between the workers is done and data is exchanged which is required for the next stage. Based on these observations, the algorithm can be further optimized as explained in the next section.

This is the first public available implementation on top of Apache Spark. The problem lies in the computational complexity of the computation of the distance matrix. By taking the Cartesian product, where the computational complexity is quadratic in respect to the input size, this cannot always be feasible for humongous datasets. In production a squared number of additional machines is required when increasing the input size increases linearly. This can obviously be retained by limiting the window size of the micro batching semantics, but making the windows too small might lead to unstable results as the set of data becomes too small. The architecture has proven to scale across different machines, but it can be improved by answering the following questions:
\begin{itemize}
    \item A more powerful primitive for the Cartesian product. The computation of the distance matrix is a special case as it takes the Cartesian product of itself. This edge case might be susceptible to optimization.
    \item Explore the possibility of an optimized data-structure such as the Barnes-Hut tree \cite{Barnes1986} in a distributed fashion. This will replace the Cartesian product. Instead of computing the exact distance it takes an approximation and runs in $\mathcal{O}(n \log n)$ time. This has been done in a shared memory environment \cite{Dubinski1996132}.
\end{itemize}
