\begin{savequote}[75mm] 
Nulla facilisi. In vel sem. Morbi id urna in diam dignissim feugiat. Proin molestie tortor eu velit. Aliquam erat volutpat. Nullam ultrices, diam tempus vulputate egestas, eros pede varius leo.
\qauthor{Quoteauthor Lastname} 
\end{savequote}


\chapter{Conclusion}

Section \ref{sec:conclusion} will conclude the work using the Research Question from Section \ref{sec1-researchquestions}. Next, further research is given in Section \ref{sec:futherResearch} will provide further research which is uncovered by the experiments.

\section{Conclusion \label{sec:conclusion}}

Before answering the Research question, the Research sub-questions will be answered. First, Research sub-question \ref{sub-req1}; \emph{`Which general-purpose outlier detection algorithms can potentially be scaled out'}. The background and purpose of the domain of outlier detection is given in Section \ref{sec1-motivation}. The definition of outlier detection we follow; `An outlier is a data point that deviates quantitatively from the majority of the data points, according to an outlier-selection algorithm'. A more in-depth technical description of outlier detection algorithms is given in Section \ref{sec:outlier}. The definition of a general purpose outlier detection algorithm and the conditions that the algorithms has to conform to is given. Next, an introduction is given in the different types of outlier detection algorithms and their potential pitfalls. An overview of different algorithms is given in Section \ref{sec:outlier} based on the given constraints. 
Outlier detection is part of the field of Knowledge Discovery and Data Mining and the computational platform to scale and distribute the algorithm is rarely taken into account. Therefore, the second Research sub-question \ref{sub-req2} focuses on the field of big-data and distributed computing to explorer the possibilities of scaling; \emph{`Which computational engines are appropriate for distributed outlier detection'}. The term `big-data' is an ambiguous terms, therefore a definition is in place, Section \ref{sec:webscale} defines it as; `massively parallel software running on tens, hundreds, or even thousands of servers'. Many  outlier-detection algorithm do not take scalability into account and solely focus on the ability to distinct outlier from inliers. The aim is to scale outlier detection on a large pool of easily accessible virtualized resources, which can be dynamically reconfigured to adjust to a variable load. The algorithm proposed in Chapter \ref{chap:architecture} enables to scale to algorithm by adding or removing additional worker based on load or requirements. By wrapping applications inside Docker containers enables fast deployment onto a large number of machines. As the number of machines increases, it becomes more probable that one of the machines will fail, therefore availability is guaranteed using Apache Zookeeper which provides reliable distributed coordination.
The last Research sub-question \ref{sub-req3}; \emph{`How to adapt the algorithm to work with streams of data, rather than a static set'}. As in today's world data is a continuously changing nature. Data is generated faster and data real-time processing is required to act upon whats happening right now. By using the Spark Streaming library and the Apache Kafka data source this is possible to realize.

Chapter \ref{chap:results} presents the results of the Stochastic Outlier Selection algorithm implementation given in Chapter \ref{chap:algorithm}. The results are generated by the architecture as defined in Chapter \ref{chap:architecture}. From this study we observe that:

\begin{itemize} 
    \item A distributed implementation of outlier detection works and follows the computational complexity of the algorithm $\mathcal{O}(n^{2})$ as a function of the input size.
    \item The proper number of partitions has to be chosen to utilize the resources of the cluster optimal. 
    \item The configuration of Apache Spark has to be tuned to the specifications of the systems to avoid unnecessary swapping which induces significant overhead and slows down the computations.
\end{itemize}

\section{Further research \label{sec:futherResearch}}




